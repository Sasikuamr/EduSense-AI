# EduSense-AI ğŸ“ğŸ¤–  
### Real-Time AI Classroom Engagement & Emotion Intelligence System

EduSense-AI is a full-stack AI-powered classroom analytics platform that measures student engagement, detects emotions, and provides live classroom insights using Computer Vision and Vision Transformers.

The system processes real-time student video streams, classifies emotional states using a Hugging Face Vision Transformer model, computes dynamic engagement scores, and visualizes classroom analytics in an interactive teacher dashboard.

---

# ğŸ“¸ Application Preview

## ğŸ¥ Student Emotion Detection

### Neutral Detection
<img width="1912" height="1183" alt="Screenshot 2026-02-24 225550" src="https://github.com/user-attachments/assets/eba9627d-3e6b-478f-8582-c97cdbd4a527" />


### Happy Detection
<img width="1919" height="1199" alt="Screenshot 2026-02-24 225603" src="https://github.com/user-attachments/assets/08c64241-b6fb-44e1-ab89-2c18190e8184" />


---

## ğŸ” Teacher Login Portal
<img width="1919" height="1174" alt="Screenshot 2026-02-24 225816" src="https://github.com/user-attachments/assets/d847450e-4ff9-4f4e-9447-39afe93d870c" />


---

## ğŸ“ Student Join Page
<img width="1914" height="1175" alt="Screenshot 2026-02-24 225823" src="https://github.com/user-attachments/assets/36c27d2c-b172-4350-8ca5-e632d0fd1cb8" />


---

# ğŸ—ï¸ System Architecture

## ğŸ”¹ Backend
- Python 3
- FastAPI
- Uvicorn
- WebSockets (real-time communication)
- SQLAlchemy (ORM)
- PostgreSQL (Database)

## ğŸ”¹ AI/ML Engine
- OpenCV (Face & Eye Detection)
- Hugging Face Transformers
- `trpakov/vit-face-expression` (Vision Transformer for 7-emotion classification)

## ğŸ”¹ Frontend â€“ Teacher Dashboard
- React
- Vite
- Tailwind CSS v4
- Recharts (Live analytics visualization)

## ğŸ”¹ Frontend â€“ Student App
- React
- Vite
- Tailwind CSS v4
- WebRTC Camera API (Live frame broadcasting)

---

# âš™ï¸ How It Works

1. The Student App captures webcam video using WebRTC.
2. Frames are sent to backend via WebSockets.
3. OpenCV detects faces and eyes.
4. Vision Transformer classifies emotion.
5. Engagement score is computed.
6. Data stored in PostgreSQL.
7. Teacher Dashboard updates live via WebSockets.
8. Recharts displays analytics.

---

# ğŸ­ AI Capabilities

## 7 Detected Emotions

- ğŸ˜„ Happy  
- ğŸ˜ Neutral  
- ğŸ˜² Surprise  
- ğŸ˜¢ Sad  
- ğŸ˜  Angry  
- ğŸ¤¢ Disgust  
- ğŸ˜¨ Fear  

The model downloads automatically on first backend boot.

---

# ğŸ“Š Engagement Scoring System

**Engagement Score Range:** 0% â€“ 100%  
Calculated up to 10 times per second per student.

### ğŸ”¢ Engagement Calculation Logic

#### 1ï¸âƒ£ Hardware Presence (30%)
- Face detected â†’ +30%
- No face â†’ 0%

#### 2ï¸âƒ£ Eye Tracking (40%)
- Eyes focused toward screen â†’ +40%

#### 3ï¸âƒ£ Emotional Context (-10% to +30%)

| Emotion   | Adjustment |
|-----------|------------|
| Happy     | +30% |
| Surprise  | +30% |
| Neutral   | +15% |
| Sad       | +5% |
| Fear      | +5% |
| Disgust   | +5% |
| Angry     | -10% |

Final score is capped at **100%**.

---

# ğŸš€ Quick Start Guide

You need **3 terminal windows** to run the full stack.

---

## 1ï¸âƒ£ Start Backend (AI + API + Database Layer)

```bash
cd backend

# Activate virtual environment
.\venv\Scripts\Activate.ps1     # Windows
# source venv/bin/activate      # Mac/Linux

# Start FastAPI server
uvicorn app.main:app --reload --port 8000
